{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6808436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import Conv3D\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import ConvLSTM2D\n",
    "from tensorflow.python.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers import concatenate\n",
    "from tensorflow.python.keras.layers import Conv3DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Models:\n",
    "\t\n",
    "\n",
    "\tdef sendec_block(input_tensor1, input_tensor2):\n",
    "\t\tx = Conv3DTranspose(filters=16, kernel_size=(2, 3, 3), strides=(1, 2, 2), \n",
    "\t\t\tpadding='same', data_format='channels_last')(input_tensor1) \n",
    "\t\tx = concatenate([input_tensor2, x], axis=-1) \n",
    "\t\tx = BatchNormalization()(x)\t\n",
    "\t\tx = Conv3D(filters=16, kernel_size=(1, 3, 3), strides=(1, 1, 1), \n",
    "\t\t\tactivation='relu', padding='same', data_format='channels_last')(x)\n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "\tdef sendec_block1(input_tensor):\n",
    "\t\tx1 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 2, 2),\n",
    "\t\t               activation='relu',\n",
    "\t\t               padding='same', data_format='channels_last')(input_tensor)\n",
    "\t\tx = Conv3DTranspose(filters=16, kernel_size=(2, 3, 3), strides=(1, 2, 2), \n",
    "\t\t\tpadding='same', data_format='channels_last')(x1) \n",
    "\t\tx = concatenate([input_tensor, x], axis=-1) \n",
    "\t\tx = BatchNormalization()(x)\t\n",
    "\t\tx = Conv3D(filters=16, kernel_size=(1, 3, 3), strides=(1, 1, 1), \n",
    "\t\t\tactivation='relu', padding='same', data_format='channels_last')(x)\n",
    "\n",
    "\t\treturn x1, x\n",
    "\n",
    "\n",
    "\n",
    "\tdef _sEnDec_cnn_lstm(input_dim, dp):\n",
    "\n",
    "\t\tprint('[INFO] Creating sEnDec_cnn_lstm Model...\\n')\n",
    "\t\tinput_layer = Input(shape=input_dim)\n",
    "\t\tseq0 = Conv3D(filters=16, kernel_size=(1, 3, 3), strides=(1, 1, 1),\n",
    "\t\t               activation='relu',\n",
    "\t\t               padding='same', data_format='channels_last')(input_layer)\t\n",
    "\n",
    "\t\t# - SEnDec block 1\n",
    "\t\tseq1, seq12 = Models.sendec_block1(seq0)\n",
    "\n",
    "\t\tseq13 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 2, 2),\n",
    "\t\t               activation='relu',\n",
    "\t\t               padding='same', data_format='channels_last')(seq12)  \n",
    "\t\t\n",
    "\t\t# - SEnDec block 2\n",
    "\t\tseq2, seq22 = Models.sendec_block1(seq13)\n",
    "\n",
    "\t\tseq22 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 2, 2),\n",
    "\t\t               activation='relu',\n",
    "\t\t               padding='same', data_format='channels_last')(seq22)\n",
    "\t\t\n",
    "\t\t# - SEnDec block 3\n",
    "\t\tseq30, seq32 = Models.sendec_block1(seq22)\n",
    "\n",
    "\t\tseq3 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 2, 2),\n",
    "\t\t               activation='relu',\n",
    "\t\t               padding='same', data_format='channels_last')(seq32) \n",
    "\t\tseq4 = ConvLSTM2D(filters=16, kernel_size=(3, 3), strides=(2, 2),\n",
    "\t\t        activation='relu', padding='same', return_sequences=True)(seq3) \n",
    "\n",
    "        \n",
    "\t\t#-~~~~~~~~~~~~~~~~~~ Upsampling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\t\t      \t               \n",
    "\t\tseq6 = Conv3DTranspose(filters=16, kernel_size=(2, 3, 3), \n",
    "\t\t\t\tstrides=(1, 2, 2), padding='same', data_format='channels_last')(seq4) \t\n",
    "\t\tseq6 = concatenate([seq6, seq3], axis=-1) \n",
    "\t\t\n",
    "\t\tseq6 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 1, 1), padding='same', data_format='channels_last')(seq6)\n",
    "\t\tseq6 = BatchNormalization()(seq6)\n",
    "\t\tseq6 = Activation('relu')(seq6)\n",
    "\t\tseq6 = concatenate([seq6, seq30], axis=-1)       \n",
    "\t\t\n",
    "\t\tseq7 = Conv3DTranspose(filters=16, kernel_size=(2, 3, 3), \n",
    "\t\t\t\tstrides=(1, 2, 2), padding='same', data_format='channels_last')(seq6) \n",
    "\t\tseq7 = concatenate([seq7, seq22], axis=-1) \n",
    "\t\t              \n",
    "\t\tseq7 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 1, 1), padding='same', data_format='channels_last')(seq7)\n",
    "\t\tseq7 = BatchNormalization()(seq7)\n",
    "\t\tseq7 = Activation('relu')(seq7)\n",
    "\t\tseq7 = concatenate([seq7, seq2], axis=-1) \n",
    "\t\t\n",
    "\t\tseq8 = Conv3DTranspose(filters=16, kernel_size=(2, 3, 3), \n",
    "\t\t\t\tstrides=(1, 2, 2), padding='same', data_format='channels_last')(seq7)  \n",
    "\t\tseq8 = concatenate([seq8, seq13], axis=-1) \n",
    "\t\tseq8 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 1, 1), padding='same', data_format='channels_last')(seq8)\n",
    "\t\t\n",
    "\t\tseq8 = BatchNormalization()(seq8)\n",
    "\t\tseq8 = Activation('relu')(seq8)\n",
    "\t\tseq8 = concatenate([seq8, seq1], axis=-1) \n",
    "\t\t\n",
    "\t\tseq9 = Conv3DTranspose(filters=16, kernel_size=(2, 3, 3), \n",
    "\t\t\t\tstrides=(1, 2, 2), padding='same', data_format='channels_last')(seq8) \n",
    "\t\tseq9 = concatenate([seq9, seq0], axis=-1) \n",
    "\t\tseq9 = Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 1, 1), padding='same', data_format='channels_last')(seq9)\n",
    "\t\t\n",
    "\t\tseq9 = BatchNormalization()(seq9)\n",
    "\t\tseq9 = Activation('relu')(seq9)\n",
    "\n",
    "\n",
    "\t\tseq91 = Dropout(dp)(seq9)\n",
    "\n",
    "\t\toutput_layer = Conv3D(filters=1, kernel_size=(2, 3, 3), strides=(1, 1, 1),\n",
    "\t\t               activation='sigmoid',\n",
    "\t\t               padding='same', data_format='channels_last')(seq91) #240 x 320\n",
    "\n",
    "\n",
    "\n",
    "\t\tprint('[INFO] Model Creation is Completed\\n')\n",
    "\n",
    "\t\treturn Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bba4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to your video data\n",
    "video_folder = 'Avenue_Dataset/normal'  # Path to the folder containing video files\n",
    "\n",
    "# Parameters\n",
    "num_frames = 4\n",
    "frame_height = 240\n",
    "frame_width = 320\n",
    "input_shape = (num_frames, frame_height, frame_width, 1)\n",
    "dp = 0.3\n",
    "\n",
    "# Load and preprocess video data\n",
    "def preprocess_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_skip = max(1, frame_count // num_frames)  # Adjust frame skip for longer videos\n",
    "    \n",
    "    for _ in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Load and preprocess video data from different formats\n",
    "video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4') or f.endswith('.avi')]\n",
    "\n",
    "# labels are organized as 'normal' and 'anomaly' folders within the video_folder\n",
    "normal_labels = np.zeros(len(video_files))\n",
    "anomaly_labels = np.ones(len(video_files))\n",
    "\n",
    "video_data = []\n",
    "labels = []\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    video_clip = preprocess_video(video_path)\n",
    "    \n",
    "    # Split the video clip into num_frames consecutive frames\n",
    "    for i in range(0, len(video_clip), num_frames):\n",
    "        clip = video_clip[i:i+num_frames]\n",
    "        \n",
    "        if len(clip) == num_frames:\n",
    "            video_data.append(clip)\n",
    "            if 'normal' in video_folder:\n",
    "                labels.append(normal_labels)\n",
    "            elif 'anomaly' in video_folder:\n",
    "                labels.append(anomaly_labels)\n",
    "\n",
    "video_data = np.array(video_data)\n",
    "labels = np.array(labels).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff261a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose an index to display\n",
    "index_to_display = 3823\n",
    "\n",
    "# Get the video clip frames and label at the selected index\n",
    "selected_video_clip = video_data[index_to_display]\n",
    "selected_label = labels[index_to_display]\n",
    "\n",
    "# Display each frame in the video clip\n",
    "for frame in selected_video_clip:\n",
    "    plt.imshow(frame, cmap='gray')\n",
    "    plt.title(f\"Label: {selected_label}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3fd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714cb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356b63b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from keras.optimizers import Adam, SGD, Adadelta\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, Conv3DTranspose, concatenate, BatchNormalization, Activation, Dropout, ConvLSTM2D\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Create and compile the model\n",
    "model = Models._sEnDec_cnn_lstm(input_shape, dp)\n",
    "\n",
    "# Create an optimizer\n",
    "#optimizer = Adam() \n",
    "\n",
    "# Compile the model with binary cross-entropy loss and accuracy metric\n",
    "#model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[binary_accuracy])\n",
    "\n",
    "model.compile(optimizer=Adadelta(), loss=MeanSquaredError())\n",
    "\n",
    "#model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(video_data) * split_ratio)\n",
    "\n",
    "train_video = video_data[:split_index]\n",
    "test_video = video_data[split_index:]\n",
    "\n",
    "train_labels = labels[:split_index]\n",
    "test_labels = labels[split_index:]\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_video, train_video, batch_size=1, epochs=5, validation_split=0.3, verbose=1)\n",
    "\n",
    "# Save the model to a file\n",
    "model.save(\"anomaly_mdel.h5\")\n",
    "\n",
    "# Make reconstructions on test data\n",
    "reconstructions = model.predict(test_video)\n",
    "\n",
    "# You can visualize or analyze the input videos and their reconstructions as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5c1ca",
   "metadata": {},
   "source": [
    "# Reconstruction plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c360715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "\n",
    "\n",
    "# Calculate reconstructions for video data\n",
    "reconstructed_videos = model.predict(test_video)\n",
    "\n",
    "# Choose a random video clip to visualize\n",
    "sample_video_index = 1  # Change this to select a different video clip\n",
    "sample_video_original = video_data[sample_video_index]\n",
    "sample_video_reconstructed = reconstructed_videos[sample_video_index]\n",
    "\n",
    "# Visualize original and reconstructed video frames\n",
    "num_frames_to_visualize = min(num_frames, sample_video_original.shape[0])\n",
    "\n",
    "plt.figure(figsize=(10, 4 * num_frames_to_visualize))\n",
    "for i in range(num_frames_to_visualize):\n",
    "    plt.subplot(num_frames_to_visualize, 2, 2 * i + 1)\n",
    "    plt.imshow(sample_video_original[i].squeeze(), cmap='gray')\n",
    "    plt.title(f'Original Frame {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_frames_to_visualize, 2, 2 * i + 2)\n",
    "    plt.imshow(sample_video_reconstructed[i].squeeze(), cmap='gray')\n",
    "    plt.title(f'Reconstructed Frame {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865ab69",
   "metadata": {},
   "source": [
    "# Calculate reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e61e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction errors\n",
    "reconstruction_errors = np.abs(sample_video_original - sample_video_reconstructed.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate reconstruction errors\n",
    "reconstruction_errors = np.abs(sample_video_original - sample_video_reconstructed.squeeze())\n",
    "\n",
    "# Calculate the sum of errors along each frame\n",
    "sum_errors_per_frame = np.sum(reconstruction_errors, axis=(1, 2))\n",
    "\n",
    "# Plot the sum of errors using a line graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_frames_to_visualize), sum_errors_per_frame, marker='o')\n",
    "plt.xlabel('Frame Index')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.title('Anomaly Score for Each Frame')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc03c00",
   "metadata": {},
   "source": [
    "# Visualize reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfaebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate reconstruction errors\n",
    "reconstruction_errors = np.abs(sample_video_original - sample_video_reconstructed.squeeze())\n",
    "\n",
    "# Visualize reconstruction errors\n",
    "plt.figure(figsize=(10, 4 * num_frames_to_visualize))\n",
    "for i in range(num_frames_to_visualize):\n",
    "    plt.subplot(num_frames_to_visualize, 2, 2 * i + 1)\n",
    "    plt.imshow(sample_video_original[i].squeeze(), cmap='gray')\n",
    "    plt.title(f'Original Frame {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_frames_to_visualize, 2, 2 * i + 2)\n",
    "    plt.imshow(reconstruction_errors[i], cmap='hot')  # Using 'hot' colormap for visualization\n",
    "    plt.title(f'Reconstruction Error {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab07bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069de89",
   "metadata": {},
   "source": [
    "# Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate reconstruction errors\n",
    "reconstruction_errors = np.abs(sample_video_original - sample_video_reconstructed.squeeze())\n",
    "\n",
    "# Flatten the reconstruction errors\n",
    "reconstruction_errors = reconstruction_errors.flatten()\n",
    "\n",
    "# Assuming that you have ground truth labels for anomalies (0: normal, 1: anomaly)\n",
    "# Replace 'anomaly_labels' with your actual labels\n",
    "\n",
    "anomaly_labels = np.zeros(len(reconstruction_errors))\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(anomaly_labels, reconstruction_errors)\n",
    "\n",
    "# Calculate the Area Under the ROC Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69becfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
